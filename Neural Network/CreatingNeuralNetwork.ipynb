{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "f31svIolfAjZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "df = pd.read_csv('train_comment_small_50.csv', sep=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "SM9JEmpjfAji"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def clean_comment(text):\n",
        "    # Strip HTML tags\n",
        "    text = re.sub('<[^<]+?>', ' ', text)\n",
        " \n",
        "    # Strip escaped quotes\n",
        "    text = text.replace('\\\\\"', '')\n",
        " \n",
        "    # Strip quotes\n",
        "    text = text.replace('\"', '')\n",
        " \n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "colab_type": "code",
        "id": "HcSZ6Cs18T5u",
        "outputId": "ebc0537c-9ea3-4e8d-8f43-f9b7252a2078"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0     \"\\n \\n I'm sure if you worked on articles othe...\n",
              "1     D'aww! He matches this background colour I'm s...\n",
              "2     Hey man, I'm really not trying to edit war. It...\n",
              "3     \"\\n More\\n I can't make any real suggestions o...\n",
              "4      REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski\n",
              "5     The Mitsurugi point made no sense - why not ar...\n",
              "6     Don't mean to bother you \\n \\n I see that you'...\n",
              "7     \"\\n \\n  Regarding your recent edits \\n \\n Once...\n",
              "8     \"\\n Good to know. About me, yeah, I'm studying...\n",
              "9     \"\\n \\n  Snowflakes are NOT always symmetrical!...\n",
              "10    \"\\n \\n  The Signpost: 24 September 2012 \\n \\n ...\n",
              "11    \"\\n \\n Re-considering 1st paragraph edit?\\n I ...\n",
              "12    Bye! \\n \\n Don't look, come or think of commin...\n",
              "13    How could I post before the block expires? The...\n",
              "14    Not sure about a heading of 'Fight for Freedom...\n",
              "15    Praise \\n \\n looked at this article about 6 mo...\n",
              "16    I was able to post the above list so quickly b...\n",
              "17    \"\\n Well, not \"\"before the process\"\" but \"\"bef...\n",
              "18    \"\\n \\n Not at all, you are making a straw man ...\n",
              "19    Your blatant POV pushing \\n \\n Neither of you ...\n",
              "20    pretty much everyone from warren county/surrou...\n",
              "21     Would you both shut up, you don't run wikipedia.\n",
              "22      Oh, it's me vandalising?xD See here. Greetings,\n",
              "23    Website \\n \\n Hey all,\\n I was thinking of get...\n",
              "24                           Thanks reading there now !\n",
              "25    Personal attacks in Fruit Brute VfD \\n \\n My a...\n",
              "26    Transliteration of Russian place names\\n In wr...\n",
              "27                        Atheism is full of bias waste\n",
              "28    How can one defame someone who thinks the Fort...\n",
              "29    LACK OF BALANCE\\n \\n This article is seriously...\n",
              "30    Sorry about that. I had checked, but had only ...\n",
              "31    TCM \\n \\n I can find no evidence that acupress...\n",
              "32    Well, it still needs expansion in areas, citat...\n",
              "33    A redirect somewhere couldn't hurt, though I s...\n",
              "34    Meivazhi\\n I've had a go at restarting the Mei...\n",
              "35    Though this is certainly a small article, but ...\n",
              "36    Yeah, let's merge the content. (Not sure if De...\n",
              "37    \"\\n \\n  Image:YourTransitAd.jpg \\n \\n I think ...\n",
              "38    \"\\n \\n  A cookie for you! \\n \\n  A cookie for ...\n",
              "39          LMAO, what a n00b. Go and listen to manele!\n",
              "40    06, 29 December 2007 (UTC)\\n Yep. LOL, the [[R...\n",
              "41    New WikiProject Novels initiative\\n We have be...\n",
              "42    \"\\n \\n UNBLOCK ME OR I'LL GET MY LAWYERS ON TO...\n",
              "43    \"== Attributing and classifying of personaliti...\n",
              "44    \"\\n \\n Actually, direct quotes that aren't in ...\n",
              "45    \"\\n Katelyn Faber\\n Could you weigh in at the ...\n",
              "46    Fradulent claim \\n \\n I am most certainly not ...\n",
              "47    That is quick if we only limit the discussion ...\n",
              "48    \"\\n \\n  123 18:38, July 18, 2005 (UTC)\\n \\n P....\n",
              "49    And, of course, Peiser is more than just a soc...\n",
              "Name: comment_text, dtype: object"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"comment_text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "KRe_aq0mfAjo"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df['cleaned_comment'] = df['comment_text'].apply(clean_comment)\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_comment'], df['toxic'], test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "colab_type": "code",
        "id": "An5Har1E9wV2",
        "outputId": "e6ae51d4-b410-4e58-b318-5c5405215c6e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "NK0BUVW7fAjt"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.corpus import stopwords\n",
        " \n",
        "vectorizer = CountVectorizer(binary=True, stop_words=stopwords.words('english'), \n",
        "                             lowercase=True, min_df=3, max_df=0.9, max_features=5000)\n",
        "X_train_onehot = vectorizer.fit_transform(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "colab_type": "code",
        "id": "rQZCZuzafAjz",
        "outputId": "93064200-633d-4975-d85f-98efe225de3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 500)               27500     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 501       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,001\n",
            "Trainable params: 28,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        " \n",
        "nn = Sequential()\n",
        " \n",
        "nn.add(Dense(units=500, activation='relu', input_dim=len(vectorizer.get_feature_names())))\n",
        "nn.add(Dense(units=1, activation='sigmoid'))\n",
        " \n",
        "nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "nn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "colab_type": "code",
        "id": "UQXxBfVSfAj4",
        "outputId": "a1195f7e-1cb9-435c-a681-344d4b858f53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nTypeError: 'SparseTensor' object is not subscriptable\nTraceback (most recent call last):\n\n  File \"C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 269, in __call__\n    return func(device, token, args)\n\n  File \"C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 147, in __call__\n    outputs = self._call(device, args)\n\n  File \"C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 154, in _call\n    ret = self._func(*args)\n\n  File \"C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\data_adapter.py\", line 513, in py_method\n    return [slice_array(inp) for inp in flat_inputs]\n\n  File \"C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\data_adapter.py\", line 513, in <listcomp>\n    return [slice_array(inp) for inp in flat_inputs]\n\n  File \"C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\data_adapter.py\", line 509, in slice_array\n    return training_utils.slice_arrays(\n\n  File \"C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_utils.py\", line 47, in slice_arrays\n    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n\n  File \"C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_utils.py\", line 47, in <listcomp>\n    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n\n  File \"C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_utils.py\", line 47, in <listcomp>\n    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n\nTypeError: 'SparseTensor' object is not subscriptable\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_2798]",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_onehot\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_train_onehot\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nTypeError: 'SparseTensor' object is not subscriptable\nTraceback (most recent call last):\n\n  File \"C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 269, in __call__\n    return func(device, token, args)\n\n  File \"C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 147, in __call__\n    outputs = self._call(device, args)\n\n  File \"C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 154, in _call\n    ret = self._func(*args)\n\n  File \"C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\data_adapter.py\", line 513, in py_method\n    return [slice_array(inp) for inp in flat_inputs]\n\n  File \"C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\data_adapter.py\", line 513, in <listcomp>\n    return [slice_array(inp) for inp in flat_inputs]\n\n  File \"C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\data_adapter.py\", line 509, in slice_array\n    return training_utils.slice_arrays(\n\n  File \"C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_utils.py\", line 47, in slice_arrays\n    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n\n  File \"C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_utils.py\", line 47, in <listcomp>\n    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n\n  File \"C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_utils.py\", line 47, in <listcomp>\n    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n\nTypeError: 'SparseTensor' object is not subscriptable\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_2798]"
          ]
        }
      ],
      "source": [
        "nn.fit(X_train_onehot[:-20], y_train[:-20], \n",
        "          epochs=5, batch_size=128, verbose=1, \n",
        "          validation_data=(X_train_onehot[-20:], y_train[-20:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "colab_type": "code",
        "id": "_GnSscMifAj9",
        "outputId": "3a034c4b-73be-45b7-e794-c064106cd3dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r10/10 [==============================] - 0s 135us/step\n",
            "Accuracy: 0.8999999761581421\n"
          ]
        }
      ],
      "source": [
        "scores = nn.evaluate(vectorizer.transform(X_test), y_test, verbose=1)\n",
        "print(\"Accuracy:\", scores[1]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "luM_AIsfkRUf"
      },
      "outputs": [],
      "source": [
        "nn.save('nn.hd5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Exercise 17_CreatingNeuralNetwork.ipynb",
      "provenance": [],
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
